{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ceca49e",
   "metadata": {},
   "source": [
    "# Andrea Baldinelli\n",
    "### Notebook tesina Machine Learning and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8064804",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import  pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# #se su windows\n",
    "# mpl.use('TkAgg')\n",
    "# pd.set_option('display.expand_frame_repr', False) #per non tagliare il print\n",
    "\n",
    "\n",
    "# realizzata solo per permettere di mettere il codice in pausa!\n",
    "def pause():\n",
    "    input(\"Premi <ENTER> per continuare ...\\n\")\n",
    "\n",
    "\n",
    "# IMPORT DATASET\n",
    "# DIMENSIONI DATASET: (19158, 14)\n",
    "data = pd.read_csv('/dataset/aug_train.csv')\n",
    "print(f\"\\ndimensione dataset: {data.shape}\\n\")\n",
    "\n",
    "# visualizzazione preliminare di informazioni del dataset\n",
    "# features dei campioni del dataset\n",
    "features = list(set(data.columns) - {'target'})\n",
    "print(\"lista features : \",features)\n",
    "\n",
    "#  experience', 'enrolled_university', 'city', 'major_discipline', 'last_new_job',\n",
    "# 'company_type', 'training_hours', 'city_development_index', 'enrollee_id',\n",
    "# 'company_size', 'education_level', 'gender', 'relevent_experience'\n",
    "\n",
    "\n",
    "# visualizzazione delle prime 10 colonne del dataset\n",
    "print(data.head(10),\"\\n\")\n",
    "\n",
    "# da una prima visualizzazione, sembra che ci sia qualche valore a null\n",
    "sns.heatmap(data.isnull())\n",
    "plt.title(\"valori nulli presenti nel dataset\")\n",
    "plt.show()\n",
    "\n",
    "# si può osservare come ci siano motli valori nulli all'interno della colonna \"genere\",\n",
    "# anche nella colonna \"major discipline\" e anche nelle colonne relative alla dimensione\n",
    "# dell'ultima azienda in cui i candidati hanno lavorato (\"company size\" e \"company type\")\n",
    "# prima di decidere il da farsi, dobbiamo valutare bene cosa fare\n",
    "\n",
    "# visualizzazione \"tipi\" dei dati\n",
    "print(\"\\ndomini delle features:\\n\",data.dtypes)\n",
    "\n",
    "# enrollee_id                 int64\n",
    "# city                       object\n",
    "# city_development_index    float64\n",
    "# gender                     object\n",
    "# relevent_experience        object\n",
    "# enrolled_university        object\n",
    "# education_level            object\n",
    "# major_discipline           object\n",
    "# experience                 object\n",
    "# company_size               object\n",
    "# company_type               object\n",
    "# last_new_job               object\n",
    "# training_hours              int64\n",
    "# target                    float64\n",
    "# dtype: object\n",
    "\n",
    "# sono molte features object, vanno tutte gestite\n",
    "pause()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################################################################\n",
    "# OSSERVIAMO LA LABEL 'TARGET'\n",
    "# visualizzazione distribuzione delle due classi all'interno del dataset\n",
    "target = data['target']\n",
    "target_counts = target.value_counts(dropna=False)\n",
    "print(target_counts)\n",
    "target_counts.plot.pie(labels=target_counts.index.tolist())\n",
    "plt.title(\"distribuzione delle classi \\nclassi sbilanciate\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# dataset molto sbilanciato! in percentuale\n",
    "class_0_occurrency = sum(data['target'] == 0.0)\n",
    "print(\"\\npersone che NON sono in cerca di un lavoro: \",class_0_occurrency/len(data['target']))\n",
    "print(\"persone che sono in cerca di un lavoro: \",1 - class_0_occurrency/len(data['target']))\n",
    "\n",
    "pause()\n",
    "########################################################################################################################\n",
    "# iniziammo con la feature 'CITY_DEVELOPMENT_INDEX', un coefficiente che descrive il livello\n",
    "# di sviluppo della città (indicata dalla feat city), indicato con un numero compreso tra 0 e 1\n",
    "cities_index = data['city_development_index'].value_counts(dropna=False)\n",
    "\n",
    "sns.displot(x=data['city_development_index'], kind='kde')\n",
    "plt.title(\"distribuzione della feature 'city_development_index'\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\", cities_index)\n",
    "print(\"\\nelementi nulli: \",sum(data['city_development_index'].isna())) # non ha valori nulli! molto bene!!\n",
    "\n",
    "\n",
    "# una distribuzione non \"polarizzata\"\n",
    "\n",
    "# quantizzazione in quartile, in modo da poter plottare i valori\n",
    "city_development_index = pd.qcut(data['city_development_index'],q=4,labels=False)\n",
    "print(\"numero di occorrenze: \",city_development_index.value_counts())\n",
    "sns.countplot(x=city_development_index,hue=target)\n",
    "plt.title(\"distribuzione della feature 'city_develop_index' in funzione della feature target\")\n",
    "plt.show()\n",
    "\n",
    "# sono int64, quindi non male come cosa!\n",
    "\n",
    "# LA FEAT 'city' la possiamo anche scartare, in quanto fortemente correlata con 'city_develop_index' e per questo mi porta ad\n",
    "# avere standard error elevato nella stima dei parametri\n",
    "data.drop(columns=['city'], axis=1,inplace=True)\n",
    "pause()\n",
    "\n",
    "########################################################################################################################\n",
    "# FEATURE \"GENDER\". Come già visionato all'inizio, presenta valori nulli\n",
    "# print(\"valori nulli colonna 'gender': \", sum(data['gender'].isna()))\n",
    "# # sono 4508 valori nulli, su un totale di 19158 sample. Può essere dovuto da errore, oppure potrebbe essere disponibile la voce \"non specificato\"\n",
    "# però, potremmo mettere tutto sotto Other\n",
    "\n",
    "# data['gender'] = data['gender'].fillna(value='Other')\n",
    "gender_counts = data['gender'].value_counts(dropna=False)\n",
    "gender_counts.plot.pie(labels=gender_counts.index.tolist())\n",
    "plt.title(\"distribuzione dei generi dei candidati all'interno del dataset di training\")\n",
    "plt.show()\n",
    "\n",
    "# gestiamo i valori a NaN\n",
    "data['gender'] = data['gender'].fillna(value=\"no_specified\")\n",
    "# data['gender_is_specified'] = data[(data['gender'] == 'male') | (data['gender'] == 'female')]\n",
    "\n",
    "# vediamo come influenza l'uscita la conoscenza del gender\n",
    "sns.countplot(x=data[\"gender\"],hue=target)\n",
    "plt.title(\"distribuzione del target in funzione del genere dei candidati\")\n",
    "plt.show()\n",
    "\n",
    "# mapping_value = { True: 1,\n",
    "#                   False: 0}\n",
    "# data['gender_is_specified'] = data['gender_is_specified'].map(mapping_value)\n",
    "\n",
    "\n",
    "# per renderlo operativamente applicabile, dobbiamo renderla operativamente utilizzabile\n",
    "# dobbiamo dummyzzare la feature!\n",
    "dummy1 = pd.get_dummies(data=data['gender'], prefix=\"gender\",drop_first=True)\n",
    "print(dummy1.columns)\n",
    "# aggiungiamo le nuove feature al dataframe\n",
    "\n",
    "data['gender_is_specified'] = 1 - dummy1['gender_no_specified']\n",
    "# rimuoviamo genere!\n",
    "data.drop(columns=['gender'],axis=1,inplace=True)\n",
    "print(\"lista colonne dataframe: \", data.columns)\n",
    "\n",
    "pause()\n",
    "\n",
    "########################################################################################################################\n",
    "# andiamo a valutare la feature 'RELEVENT_EXPERIENCE', indica se il candidato ha esperienza, o meno, pertinente con il lavoro di data scientist\n",
    "relevent_experience_counts = data['relevent_experience'].value_counts(dropna=False)\n",
    "print(\"valori nulli della colonna 'relevant_experience': \", sum(data['relevent_experience'].isna()))\n",
    "\n",
    "relevent_experience_counts.plot.pie(labels=data['relevent_experience'].unique())\n",
    "plt.title(\"distribuzione feature 'relevant_experience'\")\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x= data['relevent_experience'], hue=target)\n",
    "plt.title(\"distruibuzione feat_relevent_experience in funzione delle classi d'uscita\")\n",
    "plt.show()\n",
    "\n",
    "# poichè questa feat non è numerica, deve essere resa tale dummyzzando\n",
    "dummy2 = pd.get_dummies(data= data['relevent_experience'], drop_first=True)\n",
    "\n",
    "# per poter avere la feat \"in positivo\"\n",
    "data['relevant_experience'] = 1 - dummy2['No relevent experience']\n",
    "\n",
    "# PICCOLO CHECK\n",
    "# print(\"correlazione fra esperienza nel settore, del candidato e la probabilità di essere assunto\",data['relevant_experience'].corr(target))\n",
    "\n",
    "data.drop(columns=['relevent_experience'],axis=1,inplace=True)\n",
    "print(data.columns) # DEBUG\n",
    "\n",
    "pause()\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# andiamo ad approfondire la feature 'ENROLLED_UNIVERSITY'\n",
    "# descrive il tipo di corso universitario in cui il candidato è iscritto\n",
    "\n",
    "enrolled_university_counts = data['enrolled_university'].value_counts(dropna=False)\n",
    "enrolled_university_counts.plot.pie(labels=enrolled_university_counts.index.tolist())\n",
    "plt.title(\"distribuzione dei valori di 'enrolled_university'\")\n",
    "plt.show()\n",
    "# ho 386 valori a nan, non saprei come fillarli, alla peggio li rimuovo. Però ho letto la possibilità di usare Knn come filler\n",
    "# di NAN! Il punto è che, questa feat è molto sbilanciata verso No_enrollment!\n",
    "# prima rendo la feat numerica\n",
    "\n",
    "# per andare a feare un mapping\n",
    "map_values = { 'no_enrollment' : 1.0, 'Full time course': 2.0, 'Part time course':3.0}\n",
    "data['enrolled_university'] = data['enrolled_university'].map(map_values)\n",
    "\n",
    "# in una maniera non proprio corretta, \"fillo\" i valori a nan con il valore medio della feat.\n",
    "data['enrolled_university'] = data.enrolled_university.fillna(value=np.round(data['enrolled_university'].mean()))\n",
    "\n",
    "enrolled_university_counts = data['enrolled_university'].value_counts(dropna=False)\n",
    "print(\"distribuzione feat 'enrolled_university': \",enrolled_university_counts)\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot(x= data['enrolled_university'], hue= target)\n",
    "plt.title(\"distribuzione della feat enrolled_uni in funzione del target\")\n",
    "plt.show()\n",
    "\n",
    "# questa feature rimane in sospeso, perchè l'essersi iscritto in università non mi dice se poi l'ha portata a termine o meno!\n",
    "# quindi attenzione\n",
    "\n",
    "# REVERSE MAPPING dei valori\n",
    "mapp = {1.0 :'no_enrollment',\n",
    "        2.0 :'Full time course',\n",
    "        3.0 :'Part time course'}\n",
    "\n",
    "data['enrolled_university'] = data['enrolled_university'].map(mapp)\n",
    "\n",
    "enrolled_university_counts = data['enrolled_university'].value_counts(dropna=False)\n",
    "enrolled_university_counts.plot.pie(labels=enrolled_university_counts.index.tolist())\n",
    "plt.title(\"distribuzione feat 'enrolled_uni' nel Dataset, dopo il fix dei valori nan\")\n",
    "plt.show()\n",
    "\n",
    "# dummyzzazione della feature, fatta alla fine\n",
    "# non droppo enrolled_uni, la lascio e la droppo in seguito\n",
    "\n",
    "pause()\n",
    "########################################################################################################################\n",
    "# approfondiamo la variabile 'EDUCATION LEVEL'\n",
    "# come al solito andiamo ad approfondire la distribuzione della feat all'interno del dataset!\n",
    "\n",
    "edu_level_counts = data['education_level'].value_counts(dropna=False)\n",
    "print(\"distribuzione della feat education_level del candidato: \",edu_level_counts)\n",
    "\n",
    "edu_level_counts.plot.pie(labels=edu_level_counts.index.tolist())\n",
    "plt.title(\"distribuzione della feat 'education_level'\")\n",
    "plt.show()\n",
    "\n",
    "#voglio vedere la distribuzione con 'relevant_experience'\n",
    "sns.countplot(x=data['education_level'], hue=data['relevant_experience'])\n",
    "plt.title(\"distribuzione 'edu_level' in funzione della feat 'relevant_experience'\")\n",
    "plt.show()\n",
    "\n",
    "# come un po' mi aspettavo, abbiamo che per gli \"studiati\" hanno tutti molta più esperienza nel campo\"\n",
    "\n",
    "sns.countplot(x=data['education_level'], hue=data['enrolled_university'])\n",
    "plt.title(\"distribuzione 'edu_level' in funzione della feat 'enrolled_university'\")\n",
    "plt.show()\n",
    "# questo invece mi mette ancora più dubbi su quello che significa enrolled university\n",
    "# mantiene senso solo se vuol dire chi \"ATTUALMENTE\" FREQUENTA L'UNIVERSITÀ\n",
    "\n",
    "# poichè ci sono persone con la licenza elementare che sono iscritti all'università\n",
    "cleaning_education_level = data.loc[data['education_level'] == 'Primary School','enrolled_university']\n",
    "print(cleaning_education_level.value_counts(dropna=False))\n",
    "\n",
    "print(data.shape)\n",
    "data = data[~((data['education_level']=='Primary School') & (data['enrolled_university'] != 'no_enrollment'))]\n",
    "target = data['target']\n",
    "print(data.shape)\n",
    "\n",
    "sns.countplot(x=data['education_level'], hue=target)\n",
    "plt.title(\"distribuzione 'edu_level' in funzione del target\")\n",
    "plt.show()\n",
    "# in proporzione ho più laureati con target!\n",
    "\n",
    "# è una variabile sì categotica, però ordinale! Il grado scolastico va reso crescente!!!\n",
    "edu_level_mapping = {'Phd': 4, 'Masters': 3, 'Graduate': 2, 'High School': 1, 'Primary School': 0}\n",
    "data['education_level'] = data['education_level'].map(edu_level_mapping)\n",
    "# posso renderla poi dummy comunque!\n",
    "\n",
    "\n",
    "# # a questo punto,PER ORA, DROPPO LE COLONNE, ALTRIMENTI (ANCHE QUI) SOSTITUISCO CON LA MEDIA\n",
    "data['education_level'] = data['education_level'].fillna(value=np.round(data['education_level'].mean(skipna=True)))\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "print(\"correlazione 'edu_level' con 'relevant_experience'\",data['education_level'].corr(data['relevant_experience']))\n",
    "\n",
    "sns.countplot(x=data['education_level'], hue=target)\n",
    "plt.title(\"distribuzione 'edu_level' in funzione di una assunzione o meno\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pause()\n",
    "########################################################################################################################\n",
    "# controlliamo la feature 'MAJOR_DISCIPLINE'. Ovvero la materia di \"competenza\"\n",
    "print(\"valori assunti da 'major_discipline': \",data['major_discipline'].unique())\n",
    "print(\"distribuzione valori di 'major_discipline': \",data['major_discipline'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "#graficamente\n",
    "major_discipline_counts = data['major_discipline'].value_counts(dropna=False)\n",
    "major_discipline_counts.plot.pie(labels=major_discipline_counts.index.tolist())\n",
    "plt.title(\"distribuzione delle 'major_discipline'\")\n",
    "plt.show()\n",
    "\n",
    "# in un curriculum data science, è comunque avere come major discipline STEM, rispetto alle altre\n",
    "# abbiamo tanti valori a nan, questo però è quasi corretto, perchè chi ha un titolo di studio 'High school' o 'primary_school'\n",
    "# non hanno un campo di specializzazione!\n",
    "# major discipline è a nan in quei casi in cui il candidato non è un laureato et simila\n",
    "# posso fillare quei valori nulli con 'No major'!\n",
    "\n",
    "sns.countplot(x=data.loc[data['major_discipline'].isna(),'education_level'])\n",
    "plt.title(\"distribuzione dei valori nulli di major_discipline\\nin funzione del livello scolastico\")\n",
    "plt.show()\n",
    "# come ci aspettavamo, i campioni avente come valore 'High school' o 'Primary_school' non hanno una specializzazione in qualche\n",
    "# disciplina!\n",
    "\n",
    "high_school_discipline_nan = sum(data.loc[(data['education_level'] == 1) | (data['education_level']== 0),\"major_discipline\"].isna())\n",
    "print('numero di campioni nulli in major discipline \\n noto che stiamo osservando persone con \"diploma\" o licenza \"elementare\": ',high_school_discipline_nan),\n",
    "# quasi l'intero totale!\n",
    "print('numero di campioni con major discipline a 1: ', data[(data['education_level']==1) | (data['education_level']==0)].shape)\n",
    "# tutti i campioni a 1 hanno questa feat a nan!\n",
    "print(data.loc[(data['education_level'] ==1) | (data['education_level'] == 0)].shape)\n",
    "\n",
    "#vediamo distribuzione valori nulli, che conferma quanto detto\n",
    "major_discipline_distribution = data.loc[data['major_discipline'].isna(), 'education_level'].value_counts()\n",
    "print('\\ndistribuzione valori nulli', major_discipline_distribution)\n",
    "#2325 sono valori a nan semplicemente perchè il loro grado scolastico (high_school e primary_school) non li specializza!\n",
    "\n",
    "# quindi, sostituiamo quei 2325 valori nan con 'No major_discipline'. Gestione dei valori a nan\n",
    "data.loc[data['education_level']==1,'major_discipline'] = data.loc[data['education_level']==1 ,'major_discipline'].fillna(value='No Major')\n",
    "data.loc[data['education_level']==0,'major_discipline'] = data.loc[data['education_level']==0,'major_discipline'].fillna(value='No Major')\n",
    "# i restanti valori a nan\n",
    "# faccio il fill con il valore Other\n",
    "data['major_discipline'] = data['major_discipline'].fillna(value='Other')\n",
    "\n",
    "\n",
    "target = data['target']\n",
    "print(\"dopo la rimozione\",data.shape)\n",
    "\n",
    "# vediamo se abbiamo \"sistemato i null\"\n",
    "major_discipline_counts = data['major_discipline'].value_counts(dropna=False)\n",
    "major_discipline_counts.plot.pie(labels=major_discipline_counts.index.tolist())\n",
    "plt.title(\"distribuzione delle 'major_discipline' dopo il fix dei nan\")\n",
    "plt.show()\n",
    "# pause\n",
    "\n",
    "\n",
    "sns.countplot(x=data['major_discipline'], hue=target)\n",
    "plt.title(\"distribuzione delle discipline in funzione delle classi in uscita\")\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x=data['major_discipline'], hue=data['relevant_experience'])\n",
    "plt.title(\"distribuzione delle discipline in funzione della relevant experience\")\n",
    "plt.show()\n",
    "# pause\n",
    "\n",
    "\n",
    "\n",
    "# poichè il focus del tutto è assumere persone con curriulum data science, posso  dummyzzare così\n",
    "dummy3 = pd.get_dummies(data=data['major_discipline'],prefix='competence',drop_first=True)\n",
    "data = pd.concat([data, dummy3['competence_STEM'],dummy3['competence_No Major']], axis=1)\n",
    "data.drop(columns=['major_discipline'],axis=1,inplace=True)\n",
    "\n",
    "print(\"\\ncontrollo aggiunta nuova feature andato a buon fine\\n\",data.columns)\n",
    "\n",
    "\n",
    "\n",
    "pause()\n",
    "\n",
    "# ######################################################################################################################\n",
    "# osserviamo la feature 'EXPERIENCE', Indica l'esperienza totale del candidato, espressa in anni\n",
    "\n",
    "print(\"distribuzione dei valori della feature experience\",data['experience'].value_counts(dropna=False))\n",
    "# 53 valori nulli\n",
    "data['experience'].value_counts().plot.pie(labels= data['experience'].value_counts().index.tolist())\n",
    "plt.title(\"distribuzione dei valori della feature experience\")\n",
    "plt.show()\n",
    "\n",
    "# o vuol dire che sono persone che non hanno mai lavorato, oppure sono appena usciti dal percorso di studio\n",
    "# posso andare a verificare la distribuzione dei valori nulli\n",
    "\n",
    "# verifichiamo come si distribuiscono in funzione del titolo di studio\n",
    "nan_experience_distribution = data.loc[data['experience'].isnull(), 'education_level']\n",
    "print(\"distribuzione valori nulli di experience, in funzione del loro grado di educazione scolastica\",nan_experience_distribution.value_counts())\n",
    "\n",
    "nan_experience_distribution.value_counts().plot.pie(labels=nan_experience_distribution.value_counts().index.tolist())\n",
    "plt.title(\"distribuzione valori nulli di experience in funzione del livello di istruzione\")\n",
    "plt.show()\n",
    "\n",
    "# RESOCONTO\n",
    "# 2.0    32\n",
    "# 3.0    13\n",
    "# 1.0     4\n",
    "# 4.0     3\n",
    "# 0.0     1\n",
    "\n",
    "# anche in questo caso, ad avere nessun tipo di esperienza, sono quelli che (presumo) siano da poco usciti dal percorso scolastico\n",
    "# ergo posso considerarli come apprentice, ovvero esperienza minore di un anno\n",
    "\n",
    "#aggiungo anche la condizione che\n",
    "nan_experience = data.loc[(data['experience'].isna()) & (data['competence_STEM']==1),'relevant_experience'].value_counts()\n",
    "print(nan_experience)\n",
    "nan_experience.plot.pie(labels=nan_experience.index.tolist())\n",
    "plt.title(\"distribuzione dei valori nulli nella feat experience\\nin funzione della feature 'relevant_experience'\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# quelli 'senza esperienza' sono comunque persone con competenza e con una specializzazione STEM! Questo, assunzione mia,\n",
    "# vuol dire che molto probabilmente avranno anche la feat last_new_job a 1!!\n",
    "nan_experience_2 = data.loc[(data['experience'].isna()) & (data['competence_STEM']==1) & (data['relevant_experience']==1),'last_new_job'].value_counts()\n",
    "print(nan_experience_2)\n",
    "nan_experience_2.plot.pie(labels=nan_experience_2.index.tolist())\n",
    "plt.title(\"distribuzione dei valori nulli di experience in funzione della relevant_experience a 1\\ncompetence_STEM a 1, in funzione di last_new_job\")\n",
    "plt.show()\n",
    "\n",
    "# gestione dei valori a nan\n",
    "data['experience'] = data['experience'].fillna(value='<1')\n",
    "\n",
    "\n",
    "# <1 apprenticev\n",
    "# 1-5 junior\n",
    "# 6-10 intermediate\n",
    "# 11-15 pro\n",
    "# 16->20 senior\n",
    "\n",
    "def experience_trheshold(experience):\n",
    "\n",
    "        if (experience == '<1'):\n",
    "            return 'apprentice'\n",
    "        elif experience == '>20':\n",
    "            return 'senior'\n",
    "        elif int(experience) >= 1 and int(experience) <= 10:\n",
    "            return 'junior'\n",
    "        elif int(experience) >= 11 and int(experience) <= 19:\n",
    "            return 'pro'\n",
    "        else: # experience == 20\n",
    "            return 'senior'\n",
    "\n",
    "\n",
    "#applico funzione ad experience\n",
    "data['experience'] = data.apply(lambda x:experience_trheshold(x['experience']),axis=1)\n",
    "print(data.experience.value_counts())\n",
    "# pause()\n",
    "\n",
    "sns.countplot(x=data['experience'], hue=target)\n",
    "plt.title(\"distribuzione esperienza candidati in funzione del target\")\n",
    "# plt.show()\n",
    "# come è giusto che sia, gli apprendisti sono \"propensi a cambiare lavoro\"\n",
    "\n",
    "#voglio vedere come si modella questa feat con has experience\n",
    "sns.countplot(x=data['experience'], hue=data['relevant_experience'])\n",
    "plt.title(\"distribuzione esperienza del candidato\")\n",
    "plt.show()\n",
    "\n",
    "# come era lecito aspettarsi, tranne gli \"apprentice\" sono molti di più quelli che hanno esperienza (grosso boom dei junior)\n",
    "# invece per gli \"apprentice\", sono molti di più i candidati senza esperienza \"relativa\"\n",
    "\n",
    "\n",
    "# invece di dummyzzare, posso dire che i \"nomi\" che ho dato all'esperienza comunque hanno una certa gerarchia (ordinamento)\n",
    "# exp_map = { 'apprentice' : 1,\n",
    "#             'junior' : 2,\n",
    "#             'pro'   : 3,\n",
    "#             'senior' : 4}\n",
    "\n",
    "#data['experience'] = data['experience'].map(exp_map)\n",
    "pause()\n",
    "\n",
    "########################################################################################################################\n",
    "# andiamo a sistemare la feature 'LAST_NEW_JOB'\n",
    "\n",
    "print(\"distribuzione valori nel dataset: \",data.last_new_job.value_counts(dropna=False))\n",
    "data.last_new_job.value_counts(dropna=False).plot.pie(labels=data.last_new_job.value_counts(dropna=False).index.tolist())\n",
    "plt.title(\"distribuzione valori last_new_job nel dataset\")\n",
    "plt.show()\n",
    "\n",
    "# ci sono 381 valori a null, andiamo a vedere come si \"modellano\" in funzione dell'experience\n",
    "# verifichiamo se questo valore, coincide con persone \"apprentice\", ovvero senza troppa esperienza relativa\n",
    "sns.countplot(x=data['relevant_experience'], hue=data['last_new_job'])\n",
    "plt.title(\"distribuzione valori secondo l'esperienza 'relativa' degli iscritti\")\n",
    "plt.show()\n",
    "\n",
    "# voglio verificare anche la relazione in funzione all'esperienza dei candidati\n",
    "sns.countplot(x=data['experience'], hue=data['last_new_job'].isna())\n",
    "plt.title(\"distribuzione valori nulli secondo l'esperienza 'lavorativa' degli iscritti\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "dist_nan_experience = data.loc[data['last_new_job'].isna(), 'experience'].value_counts()\n",
    "print(dist_nan_experience)\n",
    "\n",
    "# pause\n",
    "# junior        260\n",
    "# apprentice     54\n",
    "# pro            38\n",
    "# senior         29\n",
    "\n",
    "# pause\n",
    "# in questo caso, per sistemare i valori nulli, prima di tutto trasformo in numerica la variabile e poi mi calcolo la media\n",
    "# di last_new_job in funzione del tipo di esperienza\n",
    "\n",
    "# trasformazione variabile in numerica, per poter calcolare la media\n",
    "num_mapping = { '>4': 5.0,\n",
    "                '4': 4.0,\n",
    "                '3': 3.0,\n",
    "                '2': 2.0,\n",
    "                '1': 1.0,\n",
    "                'never': 0.0}\n",
    "\n",
    "data['last_new_job'] = data['last_new_job'].map(num_mapping)\n",
    "\n",
    "unique_experience = [\"apprentice\",\"junior\",\"pro\",\"senior\"]\n",
    "relative_mean = {}\n",
    "nan_handling = data[~(data['last_new_job'].isna())]\n",
    "\n",
    "for key in unique_experience:\n",
    "    relative_mean[key] = np.round(nan_handling.loc[nan_handling['experience'] == key ,'last_new_job'].mean(skipna=True))\n",
    "    # calcolo la media in questo modo, riempo un dizionario in cui\n",
    "    # key = experience,\n",
    "    # value = la media.\n",
    "\n",
    "print(relative_mean)\n",
    "\n",
    "def apply_mean(cols):\n",
    "    # funzione che mi serve per sostituire i valori nan con la media di 'last_new_job' in funzione relativa all'esperienza del candidato\n",
    "    experience = cols[0]\n",
    "    last_new_job = cols[1]\n",
    "    if pd.isnull(last_new_job):\n",
    "        if experience == 'no_experience':\n",
    "            return  relative_mean['no_experience']\n",
    "        elif experience == 'apprentice':\n",
    "            return relative_mean['apprentice']\n",
    "        elif experience == 'junior':\n",
    "            return relative_mean['junior']\n",
    "        elif experience == 'pro':\n",
    "            return relative_mean['pro']\n",
    "        else:\n",
    "            return relative_mean['senior']\n",
    "    else:\n",
    "        return last_new_job\n",
    "\n",
    "data['last_new_job'] = data[['experience','last_new_job']].apply(apply_mean,axis=1)\n",
    "\n",
    "\n",
    "# gestiti i valori nulli\n",
    "sns.countplot(hue=data['last_new_job'],x=data.loc[data['relevant_experience']==1,'experience'])\n",
    "plt.title(\"distribuzione valori last_new_job secondo l'esperienza 'lavorativa' degli iscritti\\n(noto che hanno esperienza 'relativa')\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.countplot(x=data['last_new_job'], hue=target)\n",
    "plt.title(\"distribuzione degli anni dall'ultimo lavoro (prima dell'attuale), in funzione delle classi target\")\n",
    "plt.show()\n",
    "# C'è da dire che non è molto discrimante, visto che più o meno hanno sempre la stessa classificazione!\n",
    "\n",
    "\n",
    "pause()\n",
    "########################################################################################################################\n",
    "# # # osserviamo la feature 'COMPANY_TYPE'\n",
    "# andiamo a vedere la distribuzione della feat 'company_type'\n",
    "\n",
    "company_type_counts = data['company_type'].value_counts(dropna=False)\n",
    "print('distribuzione company_type : ', company_type_counts)\n",
    "\n",
    "# 5000 e passa valori nulli\n",
    "company_type_counts.plot.pie(labels=company_type_counts.index.tolist())\n",
    "plt.title(\"distribuzione dei valori di 'company_type' nel dataset\")\n",
    "plt.show()\n",
    "\n",
    "# gestiamo i molti valori nulli\n",
    "# verifico questi valori nulli che relazione hanno con last new job\n",
    "last_job_never = data[data['company_type'].isnull()]\n",
    "print(last_job_never.shape)\n",
    "sns.countplot(x=last_job_never['last_new_job'])\n",
    "plt.title(\"distribuzione valori nulli di company type\\nin funziione di last_new_job\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# posso incrociare i dati con la feat 'company_size'\n",
    "print('company size dei campioni con company_type nullo: ',data.loc[data['company_type'].isnull(),'company_size'].value_counts(dropna=False))\n",
    "pause()\n",
    "\n",
    "# vado a vedere come influisce questa feat nell'uscita\n",
    "sns.countplot(x=data.loc[~(data['company_type'].isna()), 'company_type'], hue=data['target'])\n",
    "plt.title(\"distribuzione della feat 'company_type', in funzione dell'uscita\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# gestione dei valori a nan, fill con la media\n",
    "map_company_type = { 'Pvt Ltd' :1, 'Funded Startup':2, 'Public Sector':3, 'Early Stage Startup':4, 'NGO':5,'Other':6 }\n",
    "\n",
    "data['company_type'] = data['company_type'].map(map_company_type)\n",
    "data['company_type'] = data['company_type'].fillna(value= np.round(data['company_type'].mean(skipna=True)))\n",
    "# oppure potevo inserire all'interno di 'Other'\n",
    "\n",
    "# reverse mapping\n",
    "reverse_mapping = { 1:'Pvt Ltd',\n",
    "    2:'Funded Startup',\n",
    "    3:'Public Sector',\n",
    "    4:'Early Stage Startup',\n",
    "    5:'NGO',\n",
    "    6:'Other'\n",
    "}\n",
    "\n",
    "pause()\n",
    "########################################################################################################################\n",
    "# gestiamo 'COMPANY_SIZE'\n",
    "company_size_counts = data['company_size'].value_counts(dropna=False)\n",
    "company_size_counts.plot.pie(labels=company_size_counts.index.tolist())\n",
    "plt.title(\"distribuzione 'company_size'\")\n",
    "plt.show()\n",
    "\n",
    "print('distribuzione valori company_size: ',company_size_counts)\n",
    "\n",
    "# AVREI PREFERITO USARE TECNICHE COME IL \"RESAMPLING VIA KNNImputer\", MA MI DA PROBLEMI.\n",
    "company_size_map = {\n",
    "    '50-99':3,\n",
    "    '100-500':4,\n",
    "    '10000+':8,\n",
    "    '10/49' :2,\n",
    "    '1000-4999' :6,\n",
    "    '<10' :1,\n",
    "    '500-999':5,\n",
    "    '5000-9999': 7\n",
    "}\n",
    "\n",
    "data['company_size'] = data['company_size'].map(company_size_map)\n",
    "data['company_size'] = data['company_size'].fillna(value= np.round(data['company_size'].mean(skipna=True)))\n",
    "\n",
    "sns.countplot(x= data['company_size'], hue=data['target'])\n",
    "plt.title(\"distribuzione 'company_size' in funzione del target\")\n",
    "plt.show()\n",
    "\n",
    "pause()\n",
    "########################################################################################################################\n",
    "# gestiamo 'TRAINING_HOURS', per vedere qualche high leverage point....\n",
    "print(\"descrizione feature 'training_hours': \",data['training_hours'].describe())\n",
    "\n",
    "training_hours = data['training_hours'].value_counts(dropna=False)\n",
    "print(\"distribuzione feature 'training_hours': \",training_hours)\n",
    "\n",
    "sns.displot(x=data['training_hours'],kind='kde')\n",
    "plt.title(\"distribuzione feature 'training_hours' \")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x=data['training_hours'], y=data['training_hours'],hue=data['target'])\n",
    "plt.title(\"verifica presenza High Leverage Points nella feat 'training_hours\")\n",
    "plt.show()\n",
    "\n",
    "training_hour = data[['training_hours','target']]\n",
    "training_hour['training_hours'] = pd.qcut(training_hour['training_hours'],q=4,labels=False)\n",
    "sns.countplot(x=training_hour['training_hours'], hue=training_hour['target'])\n",
    "\n",
    "\n",
    "plt.title(\"distribuzione feat 'training_hours' in funzione del target\")\n",
    "plt.show()\n",
    "\n",
    "pause()\n",
    "########################################################################################################################\n",
    "# ultime pulizie\n",
    "\n",
    "# perchè non sono più state rimosse queste features?\n",
    "# data.drop(columns='company_type',axis=1,inplace=True)\n",
    "# data.drop(columns='company_size',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "data.drop(columns='enrollee_id',axis=1,inplace=True)\n",
    "\n",
    "# dummyzzo la feature 'experience'\n",
    "dummy4 = pd.get_dummies(data=data['experience'],drop_first=True,prefix='experience')\n",
    "data = pd.concat([data,dummy4],axis=1)\n",
    "data.drop(columns='experience',axis=1,inplace=True)\n",
    "\n",
    "# dummyzziamo la feature enrolled university\n",
    "dummy5 = pd.get_dummies(data=data['enrolled_university'],drop_first=True)\n",
    "data = pd.concat([data,dummy5],axis=1)\n",
    "data.drop(columns='enrolled_university',axis=1,inplace=True)\n",
    "\n",
    "# rendo dummy la variabile company_type\n",
    "# prima la ritrasformo in una feature categorica nominale\n",
    "data['company_type'] = data['company_type'].map(reverse_mapping)\n",
    "dummy6 = pd.get_dummies(data['company_type'], drop_first=True, prefix='company')\n",
    "data = pd.concat([data,dummy6], axis=1)\n",
    "data.drop(columns='company_type', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# print(data.dtypes)\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(data.corr(),annot=True)\n",
    "plt.title(\"correlazione features Dataset\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# rimozione del target\n",
    "target = data['target']\n",
    "data.drop(columns='target',axis=1,inplace=True)\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "\n",
    "# droppo 'Funded_Startup', visto l'alta correlazione con un'altra feature\n",
    "data.drop(columns='company_Funded Startup',axis=1, inplace=True)\n",
    "\n",
    "print(\"dopo c'è addestramento, proseguire con catuela!!!!\")\n",
    "pause()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b1c41",
   "metadata": {},
   "source": [
    "# ADDESTRAMENTO MODELLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131b71bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ######################################################################################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m## ADDESTRAMENTO MODELLO\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# resampling con tecninca SMOTE\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      6\u001b[0m oversample \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      7\u001b[0m data, target \u001b[38;5;241m=\u001b[39m oversample\u001b[38;5;241m.\u001b[39mfit_resample(data, target)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# resampling con tecninca SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(random_state=2)\n",
    "data, target = oversample.fit_resample(data, target)\n",
    "print(data.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split training e test set\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(data,target,test_size=0.20,random_state=42,shuffle=True)\n",
    "\n",
    "m,p = X_train.shape\n",
    "# feature dummy\n",
    "X_train = np.concatenate((np.ones((m,1)), X_train), axis=1)\n",
    "\n",
    "mt,pt = X_test.shape\n",
    "# feature dummy\n",
    "X_test = np.concatenate((np.ones((mt,1)),X_test),axis=1)\n",
    "\n",
    "## standardizziamo le features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train =sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#modelli da provare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import  Pipeline\n",
    "\n",
    "\n",
    "\n",
    "# per poter avere una pipeline\n",
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "\n",
    "    def score(self): pass\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([('clf', DummyEstimator())])  # Placeholder Estimator\n",
    "\n",
    "search_space = [{'clf': [LogisticRegression()],\n",
    "                 'clf__penalty': ['l2','none'],\n",
    "                 'clf__C': np.logspace(0, 5, 20)},\n",
    "                {'clf': [MLPClassifier(max_iter=1000)],\n",
    "                 'clf__hidden_layer_sizes':[(50,), (100,),(50,50),(100, 100)],\n",
    "                'clf__alpha':[0.0001, 0.001,0.01, 0.1, 1,10,100],\n",
    "                'clf__solver':['sgd','adam'],\n",
    "                'clf__activation':['tanh','relu']}\n",
    "                # NON HO POTUTO PROVARE SVC IN QUANTO TROPPO \"LENTO\" NEL FITTING, il mio pc si \"rifiutava\"\n",
    "                # {\n",
    "                #  'clf': [svm.SVC()],\n",
    "                #  'clf__C': [0.001,0.01,0.1,1,10,30],\n",
    "                #  'clf__kernel': ['linear','rbf','poly'],\n",
    "                #  'clf__gamma': [0.01, 0.1, 1, 10, 100],\n",
    "                #  'clf__degree': [3, 5, 7]\n",
    "                #  }\n",
    "                ]\n",
    "\n",
    "\n",
    "# Create grid search CV\n",
    "model = GridSearchCV(pipe, search_space,n_jobs=-1,verbose=10,scoring='f1',cv=5)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "print(\"migliori parametri risultanti: \",model.best_params_)\n",
    "\n",
    "# verifica bontà dell'algoritmo\n",
    "Y_pred_train = model.predict(X_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# score modello\n",
    "print(\"classification report sul training: \\n\\n\",classification_report(Y_train,Y_pred_train))\n",
    "print(\"classification report sul test: \\n\\n\",classification_report(Y_test,Y_pred))\n",
    "\n",
    "# auc score, solo per completezza\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix\n",
    "print(\"metrica auc score sul training: \",roc_auc_score(Y_train, Y_pred_train, average='macro'))\n",
    "print(\"metrica auc score sul test set: \",roc_auc_score(Y_test, Y_pred, average='macro'))\n",
    "\n",
    "# CONFUSION MATRIX costruita sui campioni di test\n",
    "sns.heatmap(confusion_matrix(Y_test,Y_pred),annot=True)\n",
    "plt.title(\"confusion matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47058680",
   "metadata": {},
   "source": [
    "# RISULTATI \n",
    "## mlp classifier, SENZA LE FEATURE 'COMPANY_TYPE' e 'COMPANY_SIZE'\n",
    "\n",
    "### TRAIN\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0.0       0.76      0.83      0.79     11181\n",
    "          1.0       0.81      0.74      0.77     11230\n",
    "\n",
    "     accuracy                           0.78     22411\n",
    "    macro avg       0.79      0.78      0.78     22411\n",
    "    weighted avg       0.79      0.78      0.78     22411\n",
    "\n",
    "### TEST\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0.0       0.75      0.82      0.78      2826\n",
    "          1.0       0.80      0.72      0.76      2777\n",
    "\n",
    "     accuracy                           0.77      5603\n",
    "    macro avg       0.77      0.77      0.77      5603\n",
    "    weighted avg       0.77      0.77      0.77      5603\n",
    "\n",
    "\n",
    "\n",
    "## PROVA 2, CON LE FEAT COMPANY SIZE E TYPE \"FILLATE\" IN MANIERA NON PROPRIAMENTE CORRETTA\n",
    "\n",
    "### TRAIN\n",
    "               precision    recall  f1-score   support\n",
    "          0.0       0.83      0.82      0.82     11181\n",
    "          1.0       0.83      0.83      0.83     11230\n",
    "\n",
    "     accuracy                           0.83     22411\n",
    "    macro avg       0.83      0.83      0.83     22411\n",
    "    weighted avg       0.83      0.83      0.83     22411\n",
    "\n",
    "\n",
    "### TEST\n",
    "               precision    recall  f1-score   support\n",
    "          0.0       0.82      0.81      0.81      2826\n",
    "          1.0       0.81      0.81      0.81      2777\n",
    "\n",
    "     accuracy                           0.81      5603\n",
    "    macro avg       0.81      0.81      0.81      5603\n",
    "    weighted avg       0.81      0.81      0.81      5603\n",
    "\n",
    "\n",
    "# AUC SCORES\n",
    "TRAIN: 0.8255285390247082\n",
    "TEST: 0.812617278060787"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
